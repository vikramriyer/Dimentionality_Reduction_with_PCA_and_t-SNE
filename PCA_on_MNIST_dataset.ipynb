{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA: Principle Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding PCA with an example\n",
    "### Caveat: The example is a long one but I think you will understand it better if you read it.\n",
    "Let's say you work as a Data Scientist for an Ad Marketing Agency where your task is to analyze the data about customer purchases and find patterns as to **what made a user buy something and how can I make him/her buy more?**\n",
    "\n",
    "Now, this question we posed above can have so many follow up questions, like:\n",
    "1. Where did the user prefer buying from ? (Amazon, Flipkart, etc)\n",
    "2. What kind of add did the user click most time on? (display ads, search ads, product listing ads, email, etc)\n",
    "3. Which ad networks/channel showed most conversions? (Facebook, Google, Twitter, LinkedIn)\n",
    "4. Some complex questions can include, did a user first see an ad on Facebook and then googled up to see the best prices and buy it? <br>\n",
    "These are just some question out of the thousands that can be answered to improve user experience, customer acquisition, etc\n",
    "\n",
    "**Let's look what kind of data you may get to analyze.** Let's accept the fact that, storing the information in __RDBMS__ is not a good option because there will be lot of user tracking data that would come in various formats and very difficult to store in RDBMS. <br>\n",
    "So, this kind of tracking data is usually dumped into a __Data Warehouse__ and then various pipelines are written to extract useful ones into RDBMS to make them faster. I will not go into the details of this, if you are interested, you can read about the same with links in the references section.\n",
    "\n",
    "So without diverting from a main point, if we have huge number of data, we can just shard them and use them sequentially to keep it very simple, however, if we have more number of fields/columns/features to extract information from, then it would become really time consuming and difficult as well. **Imagine you have data about a user, which shows entire tracking of that particular user for a entire day/month/year, from various places, on various sites, on various products, at various times, from various devices, using various social accounts, etc are stored in a warehouse.**\n",
    "\n",
    "Simply put, not all of what is stored in the warehouse is useful information and hence we can exclude some of them from our analysis. But, the billion dollar question is, 'HOW'??? How do you actually find out which one is useful and which one is not? <br>\n",
    "Here, we have __PCA__ smirking at us and lending a helping hand. It says, I can choose the important features for you!\n",
    "\n",
    "So, you through maybe a __100__ features at it and it will tell you to choose __20__ of them which actually are useful in finding out information about the user.\n",
    "\n",
    "In the later sections we will see how it actually does this, with a real world example from **MNIST data set** and various steps included in it.\n",
    "\n",
    "After that, we will look at one more technique like PCA which does this better, called t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Process\n",
    "- Normalize/Standardize the data, after this step, we get a covariance Vector\n",
    "- Now find the eigenvectors and eigenvalues of this vector\n",
    "- The eigen values are scalars that have a certain magnitude\n",
    "- If eigen values for certain vectors are relatively very low, it is better to discard them off **(these are maybe the features that we were talking about which are not that useful in getting answers about the customer)**. Another way to look at this is, if some of the information is not making much sense, then its better to discard it as to reduce the dimensions and send less features to a machine learning algorithm to predict from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is normalization necessary??\n",
    "For the customer example, if the price of the commodity ranges from 1 to 1,00,00, and the quantity of items purchased will be let's say 1 to 10. <br>\n",
    "Does it not make sense to scale them so that they fall in between some rigorous value and doesn't seem like price is almost always overpowering the quantity. <br>\n",
    "\n",
    "Note that, we do not want to miss out on any useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anyways, what is a eigen vector and what does it have to do with PCA??\n",
    "It's the direction in which the data varies a lot. <br>\n",
    "Let's say we just defined the first eigen vector having the max eigen value(magnitude). The second eigen vector is the one that has maximum variance again but in the orthogonal direction of the first one; similarly, the third eigen vector is the ones that has max variance but is orthogonal to both first and second and so on if there are more dimensions..\n",
    "\n",
    "So, this eigen vector is called a Priciple Component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component ??\n",
    "Remember, we said we want to be able to discard some features, this priciple component will be used to discard these features but without losing max information. This principle compenent covers the max number of dimensions as it can by reorienting the axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we reorient the axis, seems so unreal?\n",
    "Since the principal components or the eigen vectors of the covariance matrix are orthogonal to each other, it is possible that we change the axes of the data i.e reorient the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts about PCA\n",
    "- Linear Transformation Technique\n",
    "- PCA depends on closeness of the points, and the closeness in measure as the average squared euclidean distances\n",
    "- PCA holds the directions that have the maximum spread, or variance\n",
    "- PCA ignores the class labels\n",
    "- Higher to lower dimensional without loosing much info\n",
    "- If there is corelation between data, then it makes sense to reduce the dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Implementation\n",
    "Let's play with some code to understand how difficult it is to implement PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Latex\n",
    "from IPython.display import Math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('./datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the label from the training set and add it to another variable\n",
    "label = df['label']\n",
    "df.drop('label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA implementation using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other technique (t-SNE) takes considerable amount of time on the entire dataset and my laptop almost died of one such attack, hence I am reducing(slicing) the data, so that PCA anad t-SNE comparison is easier and on\n",
    "the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below lines if slicing of the data is desired\n",
    "#df = df[:2000]\n",
    "#label = label[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing/Standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_std = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PCA instance with 5 components, i.e. dimensions, taken randomly after some experiments with other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = pca.fit(df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variance = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f86a41cf710>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD5CAYAAADodLT+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86a39fbed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data, we see not much steepness after value 75 on the x-axis, thus I will go with 75 components, to fit and transform the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pca = pca.fit_transform(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data depending on the principle components that were obtained from above step. <br>\n",
    "This is very very easy, all the part of : **covariance matrix, eigen vector calculation, eigen value calculation, choosing the top 5 ones, is done by the above line**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line will transform the data according to the new principle components, but we really want to see how it has done it, don't we??\n",
    "\n",
    "Below I have used a interactive plotting library 'plotly', the code is literally copy pasted from one of the kaggler's code and is very simple to comprehend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "trace0 = go.Scatter(\n",
    "    x = df_pca[:,0],\n",
    "    y = df_pca[:,1],\n",
    "    name = label,\n",
    "    hoveron = label,\n",
    "    mode = 'markers',\n",
    "    text = label,\n",
    "    showlegend = False,\n",
    "    marker = dict(\n",
    "        size = 8,\n",
    "        color = label,\n",
    "        colorscale ='Jet',\n",
    "        showscale = False,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(255, 255, 255)'\n",
    "        ),\n",
    "        opacity = 0.8\n",
    "    )\n",
    ")\n",
    "data = [trace0]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'Principal Component Analysis (PCA)',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "         title= 'First Principal Component',\n",
    "        ticklen= 5,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Second Principal Component',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    showlegend= True\n",
    ")\n",
    "\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot however does not show anthing significant and all the efforts put by us might feel wasted, but we actually learned where not to use PCA.\n",
    "A wise person once said, \"It's important what not to do, rather than doing what all to do!\"\n",
    "\n",
    "We will see the t-SNE notebook which makes it much more visible and the distinction between the points is very clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus (Math behind PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_std = StandardScaler().fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance matrix \n",
    "Let's start by calculating the covariance matrix, which is nothing but the normalized/standardized matrix, remember we talked above why normalization is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${CoVariance Matrix} = {1/n-1}*{\\sum_{i=1}^n (X_i - X_{mean})^T(X_i - X_{mean})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<==Covariance matrix==>> \n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "mean_vector = np.mean(df_std, axis=0)\n",
    "cov_matrix = (df_std - mean_vector).T.dot((df_std - mean_vector)) / (df_std.shape[0]-1)\n",
    "print \"<<==Covariance matrix==>> \\n{}\".format(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<==Covariance matrix==>> \n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print \"<<==Covariance matrix==>> \\n{}\".format(np.cov(df_std.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above methods, show the same results, however, its just the verbosity of the code, makes things understand better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Decomposition\n",
    "On performing the eigen decomposition on the above matrix, we get the eigen values as well as the eigen vectors (principle components) using some numpy functions, calculating of eigen vectors and values manually isn't required as we have a library to support this <br>\n",
    "**eig_vals, eig_vecs = np.linalg.eig(CoVariance_matrix)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<==Eigen Values==>>\n",
      "[  4.06964787e+01   2.91114657e+01   2.67833371e+01   2.08147194e+01\n",
      "   1.81000206e+01   1.57876737e+01   1.38244007e+01   1.25432643e+01\n",
      "   1.10638975e+01   1.00889267e+01   9.63617203e+00   8.65579470e+00\n",
      "   8.04120472e+00   7.88086691e+00   7.43637560e+00   7.16743699e+00\n",
      "   6.73538375e+00   6.61651973e+00   6.42354578e+00   6.26826675e+00\n",
      "   5.93960379e+00   5.74928832e+00   5.48826880e+00   5.32649477e+00\n",
      "   5.15217038e+00   4.94730998e+00   4.88853571e+00   4.70777145e+00\n",
      "   4.46528559e+00   4.36351702e+00   4.32543150e+00   4.22712324e+00\n",
      "   4.08726514e+00   4.06176768e+00   3.99903435e+00   3.86804997e+00\n",
      "   3.81925839e+00   3.71256507e+00   3.57437538e+00   3.45887625e+00\n",
      "   3.41436841e+00   3.36945857e+00   3.25693182e+00   3.24008824e+00\n",
      "   3.18312949e+00   3.16286640e+00   3.14244041e+00   3.09287815e+00\n",
      "   3.06368054e+00   3.02342271e+00   2.96849737e+00   2.91830693e+00\n",
      "   2.84948896e+00   2.82806029e+00   2.79589667e+00   2.76696531e+00\n",
      "   2.68974637e+00   2.63703541e+00   2.60842615e+00   2.58938021e+00\n",
      "   2.50126884e+00   2.48576071e+00   2.20802976e+00   2.24282552e+00\n",
      "   2.26576633e+00   2.44558621e+00   2.41712754e+00   2.33451020e+00\n",
      "   2.34856157e+00   2.38231165e+00   2.39156842e+00   2.21393592e+00\n",
      "   2.18219367e+00   2.14724525e+00   2.13473541e+00   2.10380281e+00\n",
      "   2.08757888e+00   2.07894080e+00   4.75373246e-03   1.88077030e-03\n",
      "   5.97321913e-04   2.03801029e+00   2.03133938e+00   2.00490133e+00\n",
      "   2.00287449e+00   1.99449324e+00   1.97689115e+00   1.96008723e+00\n",
      "   1.95636136e+00   1.93942293e+00   1.92446256e+00   1.87937806e+00\n",
      "   1.89848257e+00   1.84200398e+00   1.85551338e+00   1.82806936e+00\n",
      "   1.80457363e+00   1.79485190e+00   1.78704055e+00   1.77056345e+00\n",
      "   1.74032854e+00   1.73010661e+00   1.70906271e+00   1.68261945e+00\n",
      "   1.64494828e+00   1.67268356e+00   1.62487959e+00   1.63015678e+00\n",
      "   1.60339823e+00   1.59274839e+00   1.58361788e+00   1.52008847e+00\n",
      "   1.53504626e+00   1.55901925e+00   1.56267777e+00   1.49520235e+00\n",
      "   1.48603778e+00   1.45055614e+00   1.44459114e+00   1.43033417e+00\n",
      "   1.41795560e+00   1.39484275e+00   1.38579986e+00   1.37650895e+00\n",
      "   1.13878223e+00   1.14433133e+00   1.17802678e+00   1.35771292e+00\n",
      "   1.34771049e+00   1.34213381e+00   1.31356375e+00   1.29299011e+00\n",
      "   1.15545658e+00   1.19329954e+00   1.27261905e+00   1.24739641e+00\n",
      "   1.30493639e+00   1.16093225e+00   1.22793075e+00   1.23115097e+00\n",
      "   1.25879085e+00   1.34570698e+00   1.18916126e+00   1.26981714e+00\n",
      "   1.21762120e+00   1.13064811e+00   1.12236199e+00   8.25674163e-01\n",
      "   8.62347600e-01   1.10780517e+00   1.10288070e+00   1.09195242e+00\n",
      "   1.08405932e+00   1.08133300e+00   1.06294123e+00   1.05738260e+00\n",
      "   8.73931589e-01   8.79240514e-01   8.80187779e-01   1.04663138e+00\n",
      "   1.04507095e+00   1.04311840e+00   8.92863122e-01   8.97572899e-01\n",
      "   9.02871955e-01   1.02998178e+00   1.02558001e+00   9.07482172e-01\n",
      "   9.33037111e-01   9.29057570e-01   9.05966151e-01   9.43466664e-01\n",
      "   9.20584735e-01   9.65831160e-01   1.01540703e+00   9.51684336e-01\n",
      "   9.72246164e-01   1.00880528e+00   9.80237354e-01   9.85156455e-01\n",
      "   9.19459865e-01   9.53894115e-01   9.91308409e-01   1.00401273e+00\n",
      "   9.94638916e-01   1.00085979e+00   9.97489540e-01   1.00059511e+00\n",
      "   9.98732579e-01   6.57072661e-01   6.67469656e-01   6.74514972e-01\n",
      "   6.81612982e-01   6.86033976e-01   6.88015185e-01   6.98586791e-01\n",
      "   7.02034106e-01   7.13229040e-01   7.15415942e-01   7.84585502e-01\n",
      "   8.03255754e-01   8.11592940e-01   8.12861064e-01   7.76178902e-01\n",
      "   8.19252418e-01   7.22733581e-01   7.71126050e-01   7.63294320e-01\n",
      "   8.40676692e-01   7.52893560e-01   8.49807232e-01   7.42636328e-01\n",
      "   7.47750289e-01   7.39046734e-01   8.31539874e-01   7.58028622e-01\n",
      "   5.45699968e-01   5.55960471e-01   5.60115218e-01   5.65957087e-01\n",
      "   5.68610497e-01   5.71834852e-01   5.80874805e-01   5.84207606e-01\n",
      "   6.47560094e-01   6.44656444e-01   5.94951302e-01   5.90502358e-01\n",
      "   6.24610009e-01   6.26853394e-01   6.07370327e-01   6.13360650e-01\n",
      "   6.10604440e-01   6.35679718e-01   6.38688842e-01   6.03973922e-01\n",
      "   6.63476028e-01   4.53273625e-01   4.59936905e-01   4.67378543e-01\n",
      "   4.70889600e-01   4.74146317e-01   5.35246706e-01   4.83352924e-01\n",
      "   5.31868973e-01   5.06213771e-01   4.99094655e-01   4.87552419e-01\n",
      "   5.24854304e-01   5.13704450e-01   4.92323016e-01   4.90344290e-01\n",
      "   5.19563501e-01   5.21171138e-01   5.14673411e-01   4.92977886e-01\n",
      "   3.71892133e-01   3.79533086e-01   4.44865137e-01   4.42581515e-01\n",
      "   3.84145290e-01   3.86223501e-01   4.39246566e-01   3.90854436e-01\n",
      "   3.87473943e-01   3.98159900e-01   4.00795537e-01   4.21478409e-01\n",
      "   4.25772687e-01   4.29492020e-01   4.12930344e-01   4.07094341e-01\n",
      "   4.05414453e-01   4.16710554e-01   4.03143926e-01   4.34074136e-01\n",
      "   4.28364801e-01   4.14210541e-01   3.08783622e-01   3.12036206e-01\n",
      "   3.13972075e-01   3.18827959e-01   3.19916448e-01   3.69391173e-01\n",
      "   3.66358393e-01   3.73172176e-01   3.35520774e-01   3.40342867e-01\n",
      "   3.29214797e-01   3.47669173e-01   3.57916892e-01   3.62248115e-01\n",
      "   3.51439399e-01   3.55276687e-01   3.21341831e-01   3.38702285e-01\n",
      "   3.53444103e-01   3.28742206e-01   3.22654681e-01   3.44804820e-01\n",
      "   2.49108924e-01   2.50312901e-01   3.06327099e-01   3.03285903e-01\n",
      "   2.98252654e-01   2.95891353e-01   2.56065840e-01   2.59328865e-01\n",
      "   2.52189835e-01   2.52674271e-01   2.93156105e-01   2.63532046e-01\n",
      "   2.92655253e-01   2.89165572e-01   2.74542527e-01   2.69170325e-01\n",
      "   2.79089520e-01   2.62356076e-01   2.81779345e-01   2.71518295e-01\n",
      "   2.70766198e-01   2.88693138e-01   2.84077254e-01   2.85060320e-01\n",
      "   2.80576951e-01   2.68093590e-01   2.46769035e-01   2.43578595e-01\n",
      "   1.97737649e-01   1.98096510e-01   2.39788724e-01   1.99786715e-01\n",
      "   2.00812560e-01   2.37041838e-01   2.39172871e-01   2.34325533e-01\n",
      "   2.39559061e-01   2.05305509e-01   2.03856109e-01   2.32192697e-01\n",
      "   2.31521107e-01   2.11003393e-01   2.25467669e-01   2.23686573e-01\n",
      "   2.07362911e-01   2.27315459e-01   2.11752378e-01   2.02235560e-01\n",
      "   2.29877264e-01   2.19310570e-01   2.28369757e-01   2.13657138e-01\n",
      "   2.16085477e-01   2.07782126e-01   2.22209574e-01   2.16709922e-01\n",
      "   2.18287058e-01   1.96511555e-01   1.92617457e-01   1.91272983e-01\n",
      "   1.62976620e-01   1.63320836e-01   1.89166923e-01   1.64574788e-01\n",
      "   1.87869082e-01   1.85706416e-01   1.83902655e-01   1.83141606e-01\n",
      "   1.67019615e-01   1.69040063e-01   1.71154472e-01   1.86456483e-01\n",
      "   1.79920687e-01   1.73803618e-01   1.67363572e-01   1.69525154e-01\n",
      "   1.72545572e-01   1.77381158e-01   1.81311986e-01   1.75975867e-01\n",
      "   1.74807379e-01   1.79161251e-01   1.75273366e-01   1.38183242e-01\n",
      "   1.39131917e-01   1.40338961e-01   1.59755690e-01   1.60732414e-01\n",
      "   1.60511066e-01   1.59060560e-01   5.38750452e-15   1.41872593e-01\n",
      "  -1.59146613e-16   1.55975646e-01   1.43655513e-01   1.43918353e-01\n",
      "   1.45311681e-01  -5.65478731e-16  -2.96610127e-16   1.45952701e-01\n",
      "   1.49425967e-01   1.48261878e-01   1.52775932e-01   1.54403086e-01\n",
      "   1.51098405e-01   1.47044774e-01   1.42058242e-01   1.57171797e-01\n",
      "   1.51708097e-01   1.54029034e-01   1.57064154e-01   1.47841906e-01\n",
      "   1.17564293e-02   1.37172724e-01   1.18705982e-01   1.35870185e-01\n",
      "   1.33200749e-01   1.30123277e-01   1.29465267e-01   1.19954193e-01\n",
      "   1.34029004e-01   1.28088097e-01   1.35134046e-01   1.37531329e-01\n",
      "   1.20624176e-01   1.22589703e-01   1.26247302e-01   1.21671027e-01\n",
      "   1.24472334e-01   1.25809011e-01   1.23947335e-01   1.34644158e-01\n",
      "   1.32334859e-01   1.27080982e-01   1.20462986e-01   1.23574365e-01\n",
      "   8.45760078e-03   1.80344876e-02   1.85495902e-02   1.18317674e-01\n",
      "   1.17914265e-01   1.15593935e-01   1.17368422e-01   1.14687014e-01\n",
      "   1.16749450e-01   1.16476892e-01   1.13672068e-01   1.12424754e-01\n",
      "   1.11504809e-01   1.01967671e-01   1.08218391e-01   1.10530553e-01\n",
      "   1.09895182e-01   1.10797078e-01   1.06820525e-01   1.09462846e-01\n",
      "   1.05205740e-01   1.04111592e-01   1.07358827e-01   1.02793173e-01\n",
      "   1.05756101e-01   1.04581665e-01   1.03202582e-01   1.03327473e-01\n",
      "   2.01407766e-02   2.07778286e-02   2.11612944e-02   2.14067702e-02\n",
      "   2.20246845e-02   2.28075169e-02   2.31601784e-02   2.33458932e-02\n",
      "   2.34615511e-02   2.37827671e-02   2.40557182e-02   2.42552173e-02\n",
      "   2.44872838e-02   2.48145341e-02   2.56695209e-02   2.53681902e-02\n",
      "   2.52662650e-02   1.00911475e-01   1.01537406e-01   1.01422654e-01\n",
      "   1.00339824e-01   9.96836722e-02   9.91889457e-02   9.88925565e-02\n",
      "   9.80570318e-02   9.76705929e-02   9.72733168e-02   9.61679403e-02\n",
      "   9.67945700e-02   9.34945414e-02   9.41238871e-02   9.51440908e-02\n",
      "   9.48239916e-02   9.53971134e-02   9.25975172e-02   9.19479645e-02\n",
      "   9.31454716e-02   8.97824557e-02   9.11655073e-02   9.08395396e-02\n",
      "   9.06257749e-02   8.87926320e-02   8.99728398e-02   2.60089847e-02\n",
      "   2.63888105e-02   2.65511151e-02   2.68050276e-02   2.68907193e-02\n",
      "   2.70833655e-02   2.73991011e-02   2.76521352e-02   2.77839637e-02\n",
      "   2.81566677e-02   2.84487225e-02   2.87958485e-02   2.86279422e-02\n",
      "   3.02743156e-02   3.05483353e-02   2.98324305e-02   2.91424449e-02\n",
      "   2.95424662e-02   3.07167296e-02   2.93020097e-02   8.82818785e-02\n",
      "   8.80383536e-02   8.74535872e-02   8.59182479e-02   8.70566608e-02\n",
      "   8.69135075e-02   8.66121447e-02   8.52344712e-02   8.47282781e-02\n",
      "   8.40164489e-02   8.41810241e-02   8.37013296e-02   8.28397736e-02\n",
      "   8.31900338e-02   8.18428547e-02   8.12411740e-02   8.06071235e-02\n",
      "   8.02831545e-02   7.95154844e-02   8.08441925e-02   7.13435887e-02\n",
      "   7.91153952e-02   7.11035790e-02   7.87729700e-02   7.17394420e-02\n",
      "   7.22591767e-02   7.82804321e-02   7.28729326e-02   7.75948162e-02\n",
      "   7.32348315e-02   7.45319671e-02   7.56144841e-02   7.76918093e-02\n",
      "   7.49342097e-02   7.35825512e-02   7.36734238e-02   7.40647684e-02\n",
      "   7.60792821e-02   7.53340016e-02   7.67704119e-02   7.62856642e-02\n",
      "   7.66152753e-02   3.09266153e-02   3.13298617e-02   7.01509595e-02\n",
      "   7.03068563e-02   7.04635819e-02   3.15351062e-02   3.20274603e-02\n",
      "   3.18488389e-02   3.17456369e-02   3.28641196e-02   3.26051210e-02\n",
      "   3.23704254e-02   6.64086317e-02   6.70356913e-02   6.82317854e-02\n",
      "   6.74109497e-02   6.87226875e-02   6.93312448e-02   6.94180618e-02\n",
      "   6.90763606e-02   3.31892758e-02   3.30084575e-02   3.37610519e-02\n",
      "   3.41420046e-02   3.42649549e-02   3.57964723e-02   3.55677031e-02\n",
      "   3.48193963e-02   3.50902616e-02   3.46720315e-02   3.53633339e-02\n",
      "   3.44248768e-02   5.98907310e-02   6.03362537e-02   6.86469490e-02\n",
      "   6.12576356e-02   6.59528013e-02   6.19876230e-02   6.25433039e-02\n",
      "   6.48906241e-02   6.56177831e-02   6.07061827e-02   6.35405592e-02\n",
      "   6.75615009e-02   6.45023507e-02   6.37009709e-02   6.39677292e-02\n",
      "   6.41733599e-02   6.55875051e-02   6.23047465e-02   6.31116500e-02\n",
      "   5.88720204e-02   5.83445230e-02   6.10461667e-02   6.04994044e-02\n",
      "   5.92340139e-02   5.79520253e-02   5.94003405e-02   5.76276837e-02\n",
      "   5.70511452e-02   5.64142859e-02   5.73163743e-02   3.62346546e-02\n",
      "   5.60500297e-02   5.42257715e-02   3.64469641e-02   5.29209100e-02\n",
      "   5.26432337e-02   3.69102779e-02   3.67440441e-02   3.71633500e-02\n",
      "   3.77840909e-02   3.87454955e-02   4.20131431e-02   4.16774536e-02\n",
      "   4.31202124e-02   3.73884583e-02   3.92530371e-02   4.13158854e-02\n",
      "   4.24977918e-02   4.11508053e-02   4.04293184e-02   3.95594658e-02\n",
      "   4.07624811e-02   3.74020397e-02   3.83428564e-02   3.97656617e-02\n",
      "   3.78940543e-02   3.94446462e-02   4.01847487e-02   5.58520725e-02\n",
      "   3.83374260e-02   5.57270658e-02   5.54407637e-02   5.48946150e-02\n",
      "   5.51380741e-02   5.51210642e-02   4.02441394e-02   4.00184899e-02\n",
      "   5.35555860e-02   5.35984521e-02   4.27271678e-02   5.32855497e-02\n",
      "   4.26360416e-02   4.36005152e-02   5.07656494e-02   5.21571591e-02\n",
      "   5.19264791e-02   4.37349341e-02   5.14291040e-02   4.40941743e-02\n",
      "   4.45039024e-02   5.02345307e-02   5.01174560e-02   4.64812861e-02\n",
      "   4.96789909e-02   4.60821493e-02   4.67182388e-02   4.69657305e-02\n",
      "   4.72185987e-02   4.50029003e-02   4.84464610e-02   4.91526310e-02\n",
      "   4.87500752e-02   4.80670006e-02   4.52431605e-02   4.51191639e-02\n",
      "   4.56376799e-02   4.78897940e-02   4.34104777e-02   4.92629809e-02\n",
      "   5.12922009e-02   5.21737306e-02   4.42545198e-02   5.11155832e-02\n",
      "   4.93287526e-02   4.54685927e-02   4.75959289e-02   4.75548839e-02\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "<<==Eigen Vectors==>>\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "print \"<<==Eigen Values==>>\\n{}\".format(eig_vals)\n",
    "print \"<<==Eigen Vectors==>>\\n{}\".format(eig_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the principle components\n",
    "Now, we sort the eigen vectors in the descending order of eigen values (eig_vals above), which way we get the top principle components.\n",
    "\n",
    "We can add the eig_vals and eig_vecs in a dictionary, then do a python sort method, which will sort it in descending order like below: <br>\n",
    "\n",
    "**eigen_val_vec_pair.sort(lambda x: x[0], reverse=True)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.696478745345146, 29.111465657226773, 26.783337098645184, 20.814719425177525, 18.100020588385302, 15.787673733771211, 13.82440067523534, 12.543264267317475, 11.063897454529718, 10.088926663741347, 9.6361720251256973, 8.6557946989878545, 8.0412047193005858, 7.8808669052214411, 7.4363755986058644, 7.1674369890347185, 6.7353837546032773, 6.6165197344944167, 6.4235457822848243, 6.2682667467386528, 5.9396037896610157, 5.7492883210826715, 5.4882687976995204, 5.326494765426383, 5.1521703807913592, 4.9473099823978499, 4.8885357114429144, 4.7077714481805897, 4.4652855854057707, 4.3635170191089161, 4.3254314992026597, 4.2271232388211448, 4.0872651359168257, 4.0617676784481942, 3.9990343468594838, 3.8680499708851088, 3.819258392856729, 3.7125650719480099, 3.5743753772973945, 3.4588762492626173, 3.4143684101844789, 3.369458570920298, 3.256931822959976, 3.2400882355159566, 3.1831294853336409, 3.162866395879695, 3.1424404130328019, 3.0928781483076104, 3.0636805363599344, 3.0234227107001037, 2.9684973724005079, 2.9183069295418407, 2.8494889606298264, 2.8280602870923217, 2.7958966655617727, 2.7669653081532823, 2.6897463679131666, 2.6370354053224241, 2.6084261480315396, 2.5893802068796865, 2.5012688441116446, 2.4857607110635391, 2.4455862097776677, 2.4171275413345543, 2.3915684209006827, 2.3823116505094575, 2.3485615675747944, 2.3345101974109999, 2.2657663321249695, 2.2428255219172928, 2.2139359239265572, 2.2080297644325233, 2.1821936733385341, 2.1472452511598776, 2.1347354103328304, 2.1038028148670063, 2.0875788822512868, 2.0789407973861205, 2.0380102858040581, 2.0313393788947893, 2.0049013271480995, 2.0028744885121053, 1.9944932408561105, 1.9768911465094579, 1.9600872301673715, 1.9563613557710995, 1.9394229261481044, 1.9244625628583312, 1.8984825691346265, 1.8793780648377951, 1.8555133765725071, 1.8420039782581938, 1.8280693553874443, 1.8045736279196398, 1.7948518998102296, 1.7870405496425275, 1.7705634452102155, 1.7403285428319311, 1.7301066078373175, 1.7090627134604688, 1.6826194471242035, 1.6726835554891712, 1.6449482782359142, 1.6301567771268302, 1.6248795890000858, 1.6033982349645641, 1.5927483929022177, 1.5836178806993717, 1.5626777686473938, 1.5590192463104207, 1.5350462595999679, 1.520088471090919, 1.4952023507894108, 1.48603777626121, 1.4505561368554314, 1.4445911425878761, 1.4303341686902087, 1.4179555988867947, 1.3948427497459901, 1.3857998575325365, 1.3765089504327837, 1.3577129196384778, 1.3477104907220858, 1.3457069797931345, 1.3421338138108276, 1.3135637528649522, 1.3049363906742644, 1.2929901073524861, 1.2726190545011098, 1.2698171429228866, 1.2587908472265905, 1.2473964138054974, 1.2311509733620161, 1.2279307549186902, 1.2176211973407218, 1.1932995392338737, 1.1891612570139765, 1.178026782122334, 1.1609322536483031, 1.1554565752819403, 1.1443313295551707, 1.1387822314791651, 1.1306481053595214, 1.1223619917173642, 1.1078051694350384, 1.1028806999614724, 1.0919524189264525, 1.0840593209963625, 1.0813329985456603, 1.0629412286975786, 1.0573826017485695, 1.0466313750818641, 1.0450709496988815, 1.0431184049749578, 1.0299817818424697, 1.0255800114475866, 1.0154070260968553, 1.0088052845786499, 1.0040127343510563, 1.0008597882021046, 1.0005951096248804, 0.99873257877036481, 0.99748953971694554, 0.99463891595577869, 0.99130840872835091, 0.98515645467379986, 0.98023735430168424, 0.97224616402124009, 0.96583116001318248, 0.95389411511608091, 0.95168433573752154, 0.94346666363625309, 0.93303711091897679, 0.92905756955589125, 0.92058473496785254, 0.91945986545585212, 0.90748217206962012, 0.90596615109377965, 0.90287195478770377, 0.89757289858554912, 0.89286312152004166, 0.88018777872336373, 0.87924051361020472, 0.87393158924591041, 0.86234759975714015, 0.84980723233923372, 0.84067669205254991, 0.83153987352947889, 0.82567416256819459, 0.81925241831194362, 0.81286106360672639, 0.81159294048204766, 0.80325575444835495, 0.78458550186692533, 0.77617890155448055, 0.77112604987351374, 0.76329432025272537, 0.75802862223649681, 0.75289355961893034, 0.74775028890679029, 0.74263632792454937, 0.73904673358611506, 0.72273358120330844, 0.71541594216058813, 0.71322904010535548, 0.70203410564656477, 0.69858679127332735, 0.68801518520002092, 0.68603397583856518, 0.68161298226386902, 0.67451497233788027, 0.66746965600440522, 0.6634760276461712, 0.6570726605264634, 0.64756009351492116, 0.6446564439159006, 0.6386888422188286, 0.63567971773242415, 0.62685339413336072, 0.62461000929385069, 0.61336065023424191, 0.61060444031242234, 0.60737032651685263, 0.6039739223978301, 0.59495130221125581, 0.59050235845379018, 0.58420760628096213, 0.58087480478453568, 0.57183485168662673, 0.56861049719681889, 0.56595708681183809, 0.56011521834765865, 0.55596047117671521, 0.54569996765471407, 0.53524670616108272, 0.53186897309270953, 0.52485430409056022, 0.52117113807609905, 0.51956350128894535, 0.51467341065647698, 0.51370445048748881, 0.50621377096666886, 0.49909465538902353, 0.49297788612777121, 0.49232301573257387, 0.49034428995055052, 0.48755241883567157, 0.48335292368502053, 0.474146316668834, 0.47088959967267591, 0.46737854344058688, 0.45993690496542783, 0.4532736246345534, 0.44486513680253242, 0.44258151454631539, 0.43924656574232357, 0.43407413647905302, 0.42949202007523896, 0.4283648009323659, 0.42577268699947135, 0.42147840943771631, 0.41671055405228219, 0.4142105406858626, 0.41293034441905213, 0.40709434089192986, 0.40541445277550647, 0.40314392607577448, 0.40079553690603609, 0.39815989983713063, 0.39085443582018409, 0.38747394297647725, 0.3862235007202553, 0.38414529024421218, 0.37953308551057346, 0.37317217625597338, 0.37189213286415734, 0.36939117281528655, 0.36635839253362562, 0.36224811547606317, 0.35791689180934561, 0.35527668730756917, 0.35344410262619252, 0.35143939866172147, 0.34766917288079568, 0.34480482005039431, 0.34034286671621894, 0.33870228496806176, 0.33552077388055962, 0.32921479733758463, 0.32874220600017517, 0.32265468063046693, 0.32134183121354271, 0.31991644847452677, 0.31882795937569325, 0.31397207470364785, 0.31203620609603627, 0.30878362225810457, 0.30632709864874452, 0.30328590278339324, 0.29825265383459126, 0.29589135320787963, 0.29315610456613972, 0.29265525324100955, 0.28916557211420696, 0.28869313810792369, 0.28506032029857153, 0.28407725449627436, 0.28177934516920122, 0.28057695110608394, 0.27908952033681877, 0.27454252735702006, 0.27151829534825994, 0.27076619827069764, 0.26917032512512928, 0.26809358994388838, 0.26353204550466913, 0.26235607606513911, 0.25932886501254238, 0.25606584032883029, 0.25267427149539412, 0.25218983513115212, 0.25031290134309797, 0.24910892381072158, 0.24676903484376078, 0.24357859484895505, 0.23978872436321824, 0.2395590613032984, 0.23917287148473776, 0.2370418379794392, 0.2343255334367515, 0.23219269693573721, 0.23152110680385074, 0.22987726382878079, 0.22836975715361124, 0.2273154590522109, 0.22546766854917649, 0.22368657280562751, 0.22220957377939005, 0.21931057014913197, 0.21828705809590254, 0.21670992203160511, 0.21608547678136633, 0.21365713755425642, 0.21175237847715622, 0.21100339289769962, 0.20778212587110184, 0.20736291120433523, 0.20530550861900804, 0.20385610917347086, 0.20223556015516189, 0.2008125602386612, 0.19978671466692027, 0.19809650952264757, 0.19773764905790539, 0.19651155508307308, 0.19261745736390354, 0.19127298347362265, 0.18916692272380922, 0.18786908178195416, 0.18645648338496076, 0.1857064159098212, 0.18390265522093069, 0.18314160609915067, 0.181311986357169, 0.17992068737114045, 0.17916125097728125, 0.17738115753673458, 0.17597586702756055, 0.17527336586629846, 0.17480737909009797, 0.17380361834001873, 0.17254557245152008, 0.17115447241199944, 0.16952515407906019, 0.16904006328598614, 0.16736357214329778, 0.16701961532728934, 0.16457478764700711, 0.16332083581509527, 0.16297661950141695, 0.16073241442917943, 0.16051106570097118, 0.15975569048440447, 0.15906056030215107, 0.15717179652984567, 0.15706415418791567, 0.15597564586834603, 0.15440308577873077, 0.15402903360418238, 0.15277593196439032, 0.15170809694880943, 0.1510984045430423, 0.14942596685648243, 0.14826187792818263, 0.14784190565418887, 0.14704477417492917, 0.14595270088799833, 0.14531168086397164, 0.14391835266756844, 0.1436555134292839, 0.14205824226426381, 0.1418725930524305, 0.14033896065647009, 0.13913191699398397, 0.13818324163197124, 0.13753132914513885, 0.13717272350684798, 0.13587018542389526, 0.13513404555634234, 0.13464415791232515, 0.1340290038039311, 0.13320074893360484, 0.13233485934560529, 0.13012327694484888, 0.12946526674477568, 0.12808809701957025, 0.12708098180330279, 0.12624730176638443, 0.12580901131617578, 0.12447233402421162, 0.12394733451962239, 0.12357436519737254, 0.1225897029528546, 0.12167102686475618, 0.12062417601706339, 0.12046298558980784, 0.11995419269598702, 0.11870598244171958, 0.11831767434457036, 0.11791426509503106, 0.11736842153966096, 0.11674944989631623, 0.11647689234736799, 0.11559393466482952, 0.11468701433487005, 0.1136720678720104, 0.11242475370915278, 0.11150480934118992, 0.11079707774124135, 0.11053055285550799, 0.10989518227216473, 0.10946284560472577, 0.10821839067109895, 0.10735882680368374, 0.10682052471994732, 0.10575610070939817, 0.10520573952234834, 0.10458166541835008, 0.10411159231418834, 0.10332747272374851, 0.10320258231232879, 0.10279317250872815, 0.10196767069664865, 0.10153740615792395, 0.1014226536826546, 0.10091147466316472, 0.10033982402627709, 0.099683672158308423, 0.099188945706926365, 0.098892556462111134, 0.098057031843374387, 0.097670592918393639, 0.097273316798690154, 0.096794569955691662, 0.096167940340131722, 0.095397113358077212, 0.095144090751896768, 0.094823991558347545, 0.094123887128207268, 0.093494541371724318, 0.093145471616280437, 0.092597517227487616, 0.091947964504199398, 0.0911655073109294, 0.090839539575627279, 0.090625774912192966, 0.089972839792375747, 0.089782455709867259, 0.088792632037228356, 0.088281878464494284, 0.088038353617902756, 0.087453587188228807, 0.08705666075139494, 0.086913507477607177, 0.086612144729504528, 0.085918247943329654, 0.085234471163979961, 0.084728278053496059, 0.084181024072899166, 0.08401644889017082, 0.083701329631538937, 0.08319003375492906, 0.082839773633994238, 0.08184285471207936, 0.081241174003795338, 0.080844192542830776, 0.080607123453101392, 0.080283154506340271, 0.079515484438607439, 0.079115395174622544, 0.078772969989661809, 0.078280432096645453, 0.07769180928449268, 0.077594816192691554, 0.076770411943398051, 0.076615275268352684, 0.076285664171091491, 0.076079282149041375, 0.075614484133202028, 0.075334001617280544, 0.074934209740801325, 0.074531967135685759, 0.074064768436747128, 0.073673423777093641, 0.073582551228424886, 0.073234831518962235, 0.072872932600407697, 0.072259176705583086, 0.071739442011339777, 0.071343588681747505, 0.071103579005918988, 0.070463581894992647, 0.070306856256760697, 0.070150959492265519, 0.069418061778847961, 0.069331244753428639, 0.069076360557512956, 0.068722687457597881, 0.068646949040275018, 0.068231785356138969, 0.067561500921141257, 0.067410949697907563, 0.067035691283091836, 0.06640863165158542, 0.065952801281627046, 0.065617783104656574, 0.065587505136247587, 0.064890624146893075, 0.064502350698149191, 0.064173359854261758, 0.063967729244129079, 0.063700970922214037, 0.063540559213320955, 0.063111649969220779, 0.062543303940269385, 0.062304746525934943, 0.061987623000195599, 0.061257635605889163, 0.061046166650999378, 0.060706182680904296, 0.06049940439601055, 0.060336253690956305, 0.059890730985847192, 0.059400340523591728, 0.05923401391436086, 0.058872020402538083, 0.05834452303380816, 0.057952025298365413, 0.057627683663993706, 0.057316374333978529, 0.057051145188114029, 0.056414285887455777, 0.056050029665133373, 0.055852072541900902, 0.055727065753526026, 0.055440763650756293, 0.055138074124427054, 0.055121064201256266, 0.054894614988075456, 0.05422577152392663, 0.053598452096447376, 0.053555585989882692, 0.05328554969553468, 0.052920910026708741, 0.052643233698436223, 0.052173730585973306, 0.052157159050489212, 0.051926479080310527, 0.051429103968020001, 0.051292200887227551, 0.051115583231276615, 0.050765649352748569, 0.050234530668814302, 0.050117455959069766, 0.049678990908638469, 0.049328752575661161, 0.04926298092109143, 0.049152630970899232, 0.048750075212503255, 0.048446460959813961, 0.048067000617717841, 0.047889794009714319, 0.047595928882031978, 0.047554883859248179, 0.047218598695053432, 0.046965730531074119, 0.046718238763040057, 0.046481286067569953, 0.046082149302122732, 0.045637679894986287, 0.045468592651028879, 0.045243160473547657, 0.045119163931389941, 0.045002900320810987, 0.04450390239551915, 0.044254519820760202, 0.044094174342532155, 0.043734934126356782, 0.043600515223330222, 0.043410477687279583, 0.043120212447876394, 0.042727167750435023, 0.04263604159136402, 0.042497791758940834, 0.042013143103439066, 0.041677453627565614, 0.041315885395451377, 0.041150805287433576, 0.040762481102026647, 0.040429318350429538, 0.040244139448505405, 0.040184748712439627, 0.040018489936380908, 0.039765661749993332, 0.039559465804013538, 0.039444646243654471, 0.039253037108772294, 0.038745495549968582, 0.038342856434451018, 0.03833742598573206, 0.03789405430455859, 0.037784090920049231, 0.037402039650742111, 0.037388458302913923, 0.037163350013658655, 0.036910277923926371, 0.036744044084411155, 0.036446964079245768, 0.036234654596625504, 0.035796472293151596, 0.035567703115280902, 0.035363333860190069, 0.035090261612341279, 0.03481939633291848, 0.03467203147319585, 0.034424876766286604, 0.034264954896045176, 0.034142004555407189, 0.03376105194382073, 0.033189275763142054, 0.033008457482990604, 0.032864119605233555, 0.032605121004684073, 0.032370425355451732, 0.032027460333274554, 0.031848838873672056, 0.031745636912997442, 0.031535106192907815, 0.031329861705690153, 0.030926615338195025, 0.030716729602870849, 0.03054833533813861, 0.03027431559200389, 0.029832430503144509, 0.029542466248317776, 0.029302009718204614, 0.029142444905117408, 0.028795848458558621, 0.028627942211816106, 0.028448722462555302, 0.028156667668500435, 0.027783963736739654, 0.027652135180268041, 0.027399101141738349, 0.027083365491551829, 0.026890719293681659, 0.026805027601303478, 0.026551115058495361, 0.026388810475770286, 0.026008984671606949, 0.025669520944415079, 0.025368190209657294, 0.025266264984186187, 0.024814534141509643, 0.024487283754673538, 0.024255217304312144, 0.024055718240506157, 0.023782767086752435, 0.023461551116654274, 0.023345893156043566, 0.02316017840423636, 0.022807516936142198, 0.022024684474183816, 0.02140677017522322, 0.021161294410297501, 0.020777828640945548, 0.020140776574622175, 0.018549590223998106, 0.018034487617898682, 0.011756429312905756, 0.0084576007824636642, 0.0047537324631813623, 0.0018807703026075661, 0.00059732191341191397, 5.3875045226483292e-15, 5.6547873094987797e-16, 2.9661012717386831e-16, 1.5914661317678086e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# create pairs of the eigen values and eigen vectors so that they can be descendingly sorted w.r.t magnitude \n",
    "#of eigen values\n",
    "eigen_val_vec_pair = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# sort them in descending order of eigen values\n",
    "eigen_val_vec_pair.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# check if sorted correctly\n",
    "print [i[0] for i in eigen_val_vec_pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance for picking how many components we want to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "variance_ = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many principle components should we have/take from the above dict?\n",
    "For, this, we plot a CDF that will show us a curve and we can make a point where there is not much rise/fall in the graph, and we can choose that as the number of principle components, recheck the similar plot we drew above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f86a405f190>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZESolIXESkh/x+5kKFaElrWrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86a3a0bb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the steepness reduces after 80 on y-axis i.e. 80% variance can be explained with roughly 75-80 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation in another space/dimension\n",
    "Now, depending on the components(assume 80), we will transform the standardized data into that space, ex 5d, 6d, etc and plot a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "principle_components = []\n",
    "count = 0\n",
    "for i in eigen_val_vec_pair:\n",
    "    if count < 80:\n",
    "        principle_components.append(i[1])\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(principle_components[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = np.empty([784, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in principle_components:\n",
    "    np.append(W, np.array(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 80)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df_std.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_frame = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.084654e-315</td>\n",
       "      <td>-7.084139e-315</td>\n",
       "      <td>-7.084148e-315</td>\n",
       "      <td>-7.084130e-315</td>\n",
       "      <td>-7.084135e-315</td>\n",
       "      <td>-7.084129e-315</td>\n",
       "      <td>-7.084137e-315</td>\n",
       "      <td>-7.084141e-315</td>\n",
       "      <td>-7.084138e-315</td>\n",
       "      <td>-7.084131e-315</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.084149e-315</td>\n",
       "      <td>-7.084144e-315</td>\n",
       "      <td>-7.084138e-315</td>\n",
       "      <td>-7.084131e-315</td>\n",
       "      <td>-7.084147e-315</td>\n",
       "      <td>-7.084143e-315</td>\n",
       "      <td>-7.084145e-315</td>\n",
       "      <td>-7.084138e-315</td>\n",
       "      <td>-7.084148e-315</td>\n",
       "      <td>-7.084146e-315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404703e-314</td>\n",
       "      <td>1.404753e-314</td>\n",
       "      <td>1.404755e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404755e-314</td>\n",
       "      <td>1.404755e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404755e-314</td>\n",
       "      <td>...</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404756e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404754e-314</td>\n",
       "      <td>1.404755e-314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.128533e-314</td>\n",
       "      <td>-1.128482e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128482e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "      <td>-1.128480e-314</td>\n",
       "      <td>-1.128481e-314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.033157e-315</td>\n",
       "      <td>-7.032659e-315</td>\n",
       "      <td>-7.032641e-315</td>\n",
       "      <td>-7.032664e-315</td>\n",
       "      <td>-7.032652e-315</td>\n",
       "      <td>-7.032646e-315</td>\n",
       "      <td>-7.032650e-315</td>\n",
       "      <td>-7.032649e-315</td>\n",
       "      <td>-7.032643e-315</td>\n",
       "      <td>-7.032642e-315</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.032633e-315</td>\n",
       "      <td>-7.032655e-315</td>\n",
       "      <td>-7.032650e-315</td>\n",
       "      <td>-7.032643e-315</td>\n",
       "      <td>-7.032642e-315</td>\n",
       "      <td>-7.032649e-315</td>\n",
       "      <td>-7.032656e-315</td>\n",
       "      <td>-7.032642e-315</td>\n",
       "      <td>-7.032649e-315</td>\n",
       "      <td>-7.032654e-315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.201238e-314</td>\n",
       "      <td>2.201289e-314</td>\n",
       "      <td>2.201292e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201291e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201292e-314</td>\n",
       "      <td>...</td>\n",
       "      <td>2.201289e-314</td>\n",
       "      <td>2.201289e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "      <td>2.201291e-314</td>\n",
       "      <td>2.201291e-314</td>\n",
       "      <td>2.201291e-314</td>\n",
       "      <td>2.201293e-314</td>\n",
       "      <td>2.201289e-314</td>\n",
       "      <td>2.201289e-314</td>\n",
       "      <td>2.201290e-314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0              1              2              3              4   \\\n",
       "0 -7.084654e-315 -7.084139e-315 -7.084148e-315 -7.084130e-315 -7.084135e-315   \n",
       "1  1.404703e-314  1.404753e-314  1.404755e-314  1.404754e-314  1.404754e-314   \n",
       "2 -1.128533e-314 -1.128482e-314 -1.128481e-314 -1.128481e-314 -1.128480e-314   \n",
       "3 -7.033157e-315 -7.032659e-315 -7.032641e-315 -7.032664e-315 -7.032652e-315   \n",
       "4  2.201238e-314  2.201289e-314  2.201292e-314  2.201290e-314  2.201290e-314   \n",
       "\n",
       "              5              6              7              8              9   \\\n",
       "0 -7.084129e-315 -7.084137e-315 -7.084141e-315 -7.084138e-315 -7.084131e-315   \n",
       "1  1.404754e-314  1.404755e-314  1.404755e-314  1.404754e-314  1.404755e-314   \n",
       "2 -1.128480e-314 -1.128480e-314 -1.128482e-314 -1.128481e-314 -1.128481e-314   \n",
       "3 -7.032646e-315 -7.032650e-315 -7.032649e-315 -7.032643e-315 -7.032642e-315   \n",
       "4  2.201290e-314  2.201291e-314  2.201290e-314  2.201290e-314  2.201292e-314   \n",
       "\n",
       "       ...                   70             71             72             73  \\\n",
       "0      ...       -7.084149e-315 -7.084144e-315 -7.084138e-315 -7.084131e-315   \n",
       "1      ...        1.404754e-314  1.404754e-314  1.404754e-314  1.404754e-314   \n",
       "2      ...       -1.128481e-314 -1.128481e-314 -1.128481e-314 -1.128480e-314   \n",
       "3      ...       -7.032633e-315 -7.032655e-315 -7.032650e-315 -7.032643e-315   \n",
       "4      ...        2.201289e-314  2.201289e-314  2.201290e-314  2.201291e-314   \n",
       "\n",
       "              74             75             76             77             78  \\\n",
       "0 -7.084147e-315 -7.084143e-315 -7.084145e-315 -7.084138e-315 -7.084148e-315   \n",
       "1  1.404754e-314  1.404754e-314  1.404756e-314  1.404754e-314  1.404754e-314   \n",
       "2 -1.128480e-314 -1.128481e-314 -1.128480e-314 -1.128481e-314 -1.128480e-314   \n",
       "3 -7.032642e-315 -7.032649e-315 -7.032656e-315 -7.032642e-315 -7.032649e-315   \n",
       "4  2.201291e-314  2.201291e-314  2.201293e-314  2.201289e-314  2.201289e-314   \n",
       "\n",
       "              79  \n",
       "0 -7.084146e-315  \n",
       "1  1.404755e-314  \n",
       "2 -1.128481e-314  \n",
       "3 -7.032654e-315  \n",
       "4  2.201290e-314  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "PCA  <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html <br>\n",
    "https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/ <br>\n",
    "http://www.math.union.edu/~jaureguj/PCA.pdf\n",
    "\n",
    "Data warehousing and DBMS <br>\n",
    "https://code.facebook.com/posts/229861827208629/scaling-the-facebook-data-warehouse-to-300-pb/ <br>\n",
    "http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html <br>\n",
    "https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f <br>\n",
    "\n",
    "Digital Marketing terms <br>\n",
    "http://www.business2community.com/digital-marketing/20-must-know-digital-marketing-definitions-0797241#lva7eV0FqIrBA2a9.97 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "The tracking data is certainly very huge but the features are not too many, and may not require reduction using PCA but, to make the plot more interesting, I had to choose this example. :) <br>\n",
    "One more key point is that, PCA works on numerical data, another reason the example is not a really great fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
